{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5893ffd7-cae7-4bb5-ab64-547acc799677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing all the required libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f3a40-4cc9-4ecb-8b53-2fc552240cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "008978b9-0f2c-4614-bb9e-d03c5e5797fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30250 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Setting up the directories\n",
    "train_dir = r\"D:/data/train\"\n",
    "valid_dir = r\"D:/data/valid\"\n",
    "test_dir = r\"D:/data/test\"\n",
    "\n",
    "# Set up ImageDataGenerators for loading images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load images from directories\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(64, 64), batch_size=32, class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ab0ba4-d752-4671-8c73-513fe6e843e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930df31a-3a8e-425f-9c40-e53ca6a213bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Building a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification: wildfire or no wildfire\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553cb648-5c5a-4148-b217-9913160f9d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc46c33-27a6-4aa0-b62c-f1d0f95053b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71af37b0-283b-4d47-9023-3307b98fcf65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f110b4c-b57c-4365-a678-5f9f2c0a74e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m954s\u001b[0m 1s/step - accuracy: 0.8663 - loss: 0.3028 - val_accuracy: 0.9359 - val_loss: 0.1715\n",
      "Epoch 2/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m878s\u001b[0m 928ms/step - accuracy: 0.9308 - loss: 0.1894 - val_accuracy: 0.9506 - val_loss: 0.1294\n",
      "Epoch 3/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 842ms/step - accuracy: 0.9395 - loss: 0.1654 - val_accuracy: 0.9521 - val_loss: 0.1425\n",
      "Epoch 4/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 564ms/step - accuracy: 0.9480 - loss: 0.1427 - val_accuracy: 0.9576 - val_loss: 0.1158\n",
      "Epoch 5/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 453ms/step - accuracy: 0.9499 - loss: 0.1319 - val_accuracy: 0.9476 - val_loss: 0.1424\n",
      "Epoch 6/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 498ms/step - accuracy: 0.9533 - loss: 0.1261 - val_accuracy: 0.9571 - val_loss: 0.1172\n",
      "Epoch 7/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 522ms/step - accuracy: 0.9610 - loss: 0.1063 - val_accuracy: 0.9546 - val_loss: 0.1207\n",
      "Epoch 8/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 447ms/step - accuracy: 0.9664 - loss: 0.0914 - val_accuracy: 0.9576 - val_loss: 0.1166\n",
      "Epoch 9/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 435ms/step - accuracy: 0.9710 - loss: 0.0840 - val_accuracy: 0.9560 - val_loss: 0.1197\n",
      "Epoch 10/10\n",
      "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 431ms/step - accuracy: 0.9750 - loss: 0.0695 - val_accuracy: 0.9571 - val_loss: 0.1335\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data=valid_generator, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc233ac8-3103-419a-ba87-13970ddb8766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"wildfire_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3891bc1c-4354-4e89-97fe-ab9a64149668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and predict an image\n",
    "def predict_image():\n",
    "    # Open file dialog to select an image\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        # Display the image in the GUI\n",
    "        img = Image.open(file_path)\n",
    "        img = img.resize((200, 200))\n",
    "        img = ImageTk.PhotoImage(img)\n",
    "        image_label.configure(image=img)\n",
    "        image_label.image = img\n",
    "\n",
    "        # Preprocess the image for the model\n",
    "        img_for_model = Image.open(file_path).resize((64, 64))\n",
    "        img_array = np.array(img_for_model) / 255.0  # Rescale like during training\n",
    "        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "        # Make a prediction\n",
    "        prediction = model.predict(img_array)[0][0]\n",
    "        result = \"Wildfire\" if prediction > 0.5 else \"No Wildfire\"\n",
    "        result_label.config(text=\"Prediction: \" + result)\n",
    "\n",
    "# Setting up the GUI window\n",
    "root = tk.Tk()\n",
    "root.title(\"Forest Fire Detection\")\n",
    "root.geometry(\"400x400\")\n",
    "\n",
    "# Add widgets\n",
    "btn = tk.Button(root, text=\"Upload Image\", command=predict_image)\n",
    "btn.pack(pady=20)\n",
    "\n",
    "image_label = tk.Label(root)\n",
    "image_label.pack()\n",
    "\n",
    "result_label = tk.Label(root, text=\"Prediction: \", font=(\"Helvetica\", 16))\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175312da-2745-4a61-bfcd-96c835cdbf66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28ff85-c5a2-42cb-9796-91de19aacb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
